---
output:
  pdf_document: default
  word_document: default
fontsize: 11pt
geometry: margin=1in
---

```{r, include = FALSE }
knitr::opts_chunk$set( echo=FALSE, # hide code from document
                       warning=FALSE, # hide warnings 
                       message=FALSE) # hide messages 
library(tidyverse)
library(lubridate)
library(knitr)
library(readr)
library(kableExtra)
```

```{r, echo=FALSE, warning=FALSE, results=FALSE, message=FALSE}
#This is the initial data processing code that Prof. Damouras gave us. The only part of this block that was changed by Alec was filtering out all data points with no duration data.
library(tidyverse)
rm(list = ls())
raw_data = NULL
for( i in 1:17){
  tmp = readxl::read_xlsx( "data/STAA57 Initial Data.xlsx", skip = 1, sheet = i, 
                                     col_names =  paste( "X", 1:12, sep="" ) ) %>% 
    mutate( Instructor_ID = i,
            PPL = X1,
            X1 = replace( X1, !str_detect(X1, "Student"), NA ),
            PPL = zoo::na.locf( PPL ),
            X1 = zoo::na.locf(X1) )
  raw_data = bind_rows( raw_data, tmp )
}
rm(tmp,i)
names( raw_data  ) = c( "Student", "Year", "Month", "Day", "Aircraft", "LF_dual", 
"LF_solo", "Instrument_AC",  "Instrument_Sim", "CC_dual", "CC_solo", "Exercises",
"Instructor_ID", "Licence")
head(raw_data)
raw_data %>%
  filter( !is.na(Year), Year != "Year",
          Exercises != "*NO DATA") %>% 
  mutate_at( .vars = c(2:4), .funs = as.integer ) %>% 
  mutate_at( .vars = c(6:11), .funs = as.numeric ) %>% 
  mutate( Aircraft = str_to_upper(Aircraft),
          Aircraft = replace( Aircraft, str_detect(Aircraft, "GROUND"), "GROUND"),
          Aircraft = replace_na( Aircraft, "NA"),
          Other = ifelse( str_detect(Aircraft,"GROUND|NA"), -1, NA ),
          Student_ID = as.numeric( factor( paste( Student, Instructor_ID) ) ), 
          Session_ID = row_number() ) %>% 
  gather( key = "Training_Type", value = "Duration", 6:11, Other) %>% 
  filter( !is.na(Duration) ) %>% 
  mutate( Duration  = na_if(Duration, -1),
          Aircraft = na_if(Aircraft, "NA")) %>% 
  select( Instructor_ID, Student_ID, Session_ID, Year, Month, Day, 
          Aircraft, Duration, Training_Type, Exercises, Licence ) %>% 
          filter(! is.na(Duration)) -> clean_data
clean_data %>% 
  distinct( Session_ID, .keep_all = T) %>% 
  # split the exercises string into a "list" column w str_split()
  mutate( Exercises = str_split(Exercises, ",") ) %>%  
  # and expand list contents into multiple rows w/ unnest()
  unnest( Exercises)
  
```

```{r, echo=FALSE, warning=FALSE, message=FALSE}
#Starting here, this is my own code.
# This for loop iterates through each training session's year data. If the year is listed below 2015, it replaces the year with the year of the entries above and below it (assuming they match, but there have been no cases where they didn't in our data sets).
# This works, as by this point in the processing, sessions are sorted by date for each instructor, then by each student.
for (i in 2:nrow(clean_data)-1){
  if (clean_data[i,4] < 2015 && clean_data[i-1,4] == clean_data[i+1,4]){
    clean_data[i,4] = clean_data[i-1,4]
  }
}
#This loop does the same as the one above but with replacing month values > 12 with the month of an adjacent datapoint from the same student.
for (i in 2:nrow(clean_data)-1){
  if (clean_data[i,5] > 12 && clean_data[i-1,2] == clean_data[i,2]){
    clean_data[i,5] = clean_data[i-1,5]
  }
  else if (clean_data[i,5] > 12 && clean_data[i+1,2] == clean_data[i,2]){
    clean_data[i,5] = clean_data[i+1,5]
  }
}
# This line removes all non comma separators including periods, spaces, double commas, and backticks as well as leading and trailing commas.
clean_data$Exercises = clean_data$Exercises %>% str_replace("^,", "") %>% str_replace_all(",$", "") %>% str_replace_all("\\`", "1") %>% str_replace_all("[:punct:]", ",") %>% str_replace_all("[:blank:]", ",") %>% str_replace_all(",,", ",")
#This algorithm deletes every extra errant data points that have listed exercises above 30 (It's safer to delete these points than to assume we know what they are)
invalid_points = c()
for (i in 1:nrow(clean_data)){
  exercises = clean_data[i,10]
  is_invalid = FALSE
  last_comma = 0
  for (j in 1:nchar(exercises)){
    if (substr(exercises, j, j) ==  ","){
      q = substr(exercises, last_comma+1, j-1)
      if (strtoi(substr(exercises, last_comma+1, j-1)) > 30){
        is_invalid = TRUE
      }
      last_comma = j
    }
    if (j == nchar(exercises)){
      if (strtoi(substr(exercises, last_comma+1, j)) > 30){
        is_invalid = TRUE
      }
    }
  }
  if (is_invalid == TRUE){
    invalid_points = append(invalid_points, clean_data[i, 10])
  }
}
for (i in 1:length(invalid_points)){
  clean_data = clean_data %>% filter(Exercises != invalid_points[i])
}
```

# STAA57 W21 Draft Report 

Group 14 (Alec Larsen, Aditya Kulkarni, Vishal Sahoo, MD Wasim)    

Link to RStudio Cloud shared project: https://rstudio.cloud/spaces/115177/project/2210076

***

## Introduction 
The profitability of a flight school business is reliant upon two critical factors: The efficiency of flight training and the success of students post that training. Our analysis seeks to improve two main aspects of the training process. The first aspect is scheduling. Through our analysis, we aimed to determine whether training sessions are being scheduled efficiently, and if not, how can they be scheduled more efficiently. The second aspect of our analysis covers the ideal conditions that lead to student success. We conducted our analysis through a series of graphs, tables, and indepenedence tests to check our hypotheses.

### Data 

In answering these questions, we made the assumption that all students begin their training at the same skill level. Additionally, we assume there were no unmeasurable external factors impacting the duration or efficiency of sessions. That is to say, unless a factor can be measured, it cannot be accounted for in our analysis.

To determine when flying is the safest (least wind speed), we used weather data from Government Of Canada's Website.\
Weather data: https://climate.weather.gc.ca/historical_data/search_historic_data_e.html

This data was used to compare the weather conditions during training sessions that are currently being held to possible ideal conditions.
We will utilise the information stored in the following variables: Year, Month, Day, SPEED_MAX_GUST

```{r echo=FALSE, cache=FALSE, results=FALSE, warning=FALSE, comment=FALSE}
climate_daily <- read_csv("data/climate-daily.csv")
read_csv("data/climate-daily.csv", 
         col_types = cols(Year = col_integer(), Month = col_integer(), Day = col_integer())) %>% 
  select(Year, Month, Day, `MAX_TEMPERATURE`, `MIN_TEMPERATURE`, `MEAN_TEMPERATURE`, `HEATING_DEGREE_DAYS`,
         `COOLING_DEGREE_DAYS`, `TOTAL_PRECIPITATION`, `SPEED_MAX_GUST`) -> weather
```

Air traffic data was also used to determine the density of air traffic per month. To help determine when air traffic is the lowest, and thus flight accident risk is the lowest, we acquired air traffic data from the suggested supplementary data.\
Air Traffic - https://open.canada.ca/data/en/dataset/b91772ed-edae-4fd4-8b80-a3e4c1d29976 \
We utilise the following variables from air traffic data: Month: Month of year, Value: The number of airplanes. \

```{r, echo=FALSE, warning=FALSE, message=FALSE, fig.height = 4}
# Air Traffic Import Code
air_movements <- read_csv("data/Aircraft_Movements.csv")
air_movements %>%
  filter( Airports == "Oshawa, Ontario",  str_detect(REF_DATE, "2015|2016|2017|2018|2019|2020") ) %>%
  select( REF_DATE, `Civil and military movements`, VALUE) -> air_movements
air_movements %>%
  separate(REF_DATE, c("Year", "Month"), sep = "-") %>%
  mutate(Year = as.integer(Year), Month = as.integer(Month)) -> air_movements
```

## Analysis 

### Scheduling

```{r echo=FALSE, cache=FALSE, results=FALSE, warning=FALSE, comment=FALSE, out.width = '50%'}

#Months vs total number of sessions
clean_data %>% 
  mutate(Month = month(Month, label = T))%>%
  group_by(Month) %>% 
  summarise(Sessions = n_distinct(Session_ID)) %>% 
  ggplot(aes(x = Month, y = Sessions)) + geom_bar(stat = "identity") + ggtitle("Months vs Total Number Of Sessions") + 
  theme(plot.title = element_text(hjust = 0.5))
  
  #Speed of max gust vs month
weather%>%
  drop_na(`SPEED_MAX_GUST`) %>%
  mutate(Month = month(Month, label = T))%>%
  select(SPEED_MAX_GUST, Month)%>%
  ggplot(aes(x=Month, y=SPEED_MAX_GUST)) + geom_bar(stat = "identity") + ggtitle("Month vs Speed of Max Gust")
```
The data comparing the maximum speed of gust to the month of a year over past 5 years shows a trend line steadily increasing from January to March and then decreasing from March to the least in July. An increase is then observed from August to December. The number of sessions conducted per month for the given date range suggest that the conduction of sessions is least in the month of April from where it starts rising and reaches its maximum in August. There is a steady increase from August up to April. The rate of decline in the demand increases and becomes steady as we move through the year up to December.

```{r echo=FALSE, cache=FALSE, results=FALSE, warning=FALSE, comment=FALSE, out.width = "50%"}
#Speed of max gust vs number of sessions
  #This uses old convention for extracting season data frame. Replace with updated df.
  weather %>% drop_na(`SPEED_MAX_GUST`) %>% inner_join(clean_data, by = c("Year", "Month", "Day")) %>% ggplot(aes(x=`SPEED_MAX_GUST`)) + 
  geom_bar(stat="count") + labs(y = "Number of Sessions") + ggtitle("Speed Of Maximum Gust (km/h) vs Number Of Sessions") + 
  theme(plot.title = element_text(hjust = 0.5))
  
#Comparing air traffic for external data
seasons_four <- tibble(
  Month = 1:12,
  Season = c(rep("Winter", 2), rep("Spring", 3), rep("Summer", 3), rep("Fall", 3), "Winter"))
air_movements %>%
  inner_join(seasons_four, by = c("Month")) -> seasonal_air_movements
seasonal_air_movements %>% 
  group_by(Month) %>%
  mutate(Month = month(Month, label = T))%>%
  summarise(Traffic = mean(VALUE)) %>%
  ggplot(aes(x = Month, y = Traffic)) + geom_bar(stat = "identity") + ggtitle("Month vs Air Traffic")
```
On comparing the speed of max gust to the number of sessions being conducted during that day, we found out that as the speed of gust increases, the Number of sessions being conducted show a decline. The Air traffic per month also has a steady trend with the maximum in July and a gradual decrease till December. There is an increase from January until July. Overall the months from May to October seem the best time to fly during the year. As the Air traffic is highest in July, and the number of sessions conducted are highest in August, the flight training is much safer already. However, as the maximum speed of gust is similar during the months of September and June, and the Air Traffic is even lesser than August. The flight school training sessions can be increased in the month of September.  

We continued our analysis by establishing a reliable measure of instructor efficiency. As both the number of exercises completed and the number of hours each instructor works are continuous variables, we chose to establish an efficiency metric based on the correlation between these two variables.

```{r, echo=FALSE, warnings=FALSE, out.width = "50%"}
new_clean_data = clean_data %>% mutate(Exercise_Count = str_count(Exercises, ',') + 1, Date = as.Date(ISOdate(Year, Month, Day)))
# Graphing Information on Instructors
Instructor_Data = new_clean_data %>% group_by(Instructor_ID) %>% summarise(Total_Hours = sum(Duration), Total_Exercises = sum(Exercise_Count), Hourly_Exercises = Total_Exercises/Total_Hours, Years_Worked = as.numeric(max(Date)- min(Date))/365.25, Average_Hours = (sum(Duration)/Years_Worked))

# Graph total hours against total exercises students completed under each instructor (with line of best fit and r value
coef = cor(Instructor_Data %>% select(Total_Hours), Instructor_Data %>% select(Total_Exercises), method = c("pearson"))[1][1]
Coeftext = paste("r =" , toString(coef))
ggplot(data = Instructor_Data, aes(x = Total_Hours, y = Total_Exercises)) + geom_point()  +
  geom_smooth(method='lm', formula= y~x, se = FALSE)+  geom_text(aes(x = 250, y = 300), label = Coeftext) +
  ggtitle("Hours of Instruction by Instructors vs Total Exercises Students Completed")

ggplot(data = Instructor_Data, mapping = aes(x = Average_Hours, y = Hourly_Exercises)) + geom_point() + geom_text(aes(x = Average_Hours, y = Hourly_Exercises, label = Instructor_ID, hjust = 0), nudge_x = 1) + geom_smooth(method = 'lm', formula = y~x, se = FALSE) + ggtitle("Hours Instructed per Year vs Hourly Exercises Completed")
```

We found that the Pearson correlation coefficient was approximately `r {coef}` indicating a very strong correlation. Based on this, we concluded that the number of exercises students completed under each instructor per hour of work is a strong measure of efficiency. We believe that ideally instructors should be getting a number of hours directly proportional to their efficiency. Thus, we generated the second graph above to determine a roughly ideal distribution of hours for each instructor. Instructors whose points lie above the line are, by our model, being given too many hours relative to average efficiency and instructors below the line are being given too few hours relative to their efficiency. To maximize profits, instructors should be training students as fast as possible during the times of high demand. While there is a minimum hours limit, it is reasonable to believe that instructors that complete more exercises in a set time will have students perform better. Thus, their students will have a better chance of passing the flight exam the first time.`

### Student Success

To establish that flying solo can be considered to be a metric for students' progress we tested if there is a difference in the average number of exercises completed by students that flew solo and the number of exercises completed by students that never flew solo. Only exercises coompleted up to and including  the first solo flight count for this comparison. The first solo flight is determined to be the first session with solo in training type.

We first plotted side-by-side boxplots of the number of exercises completed by both groups of students.
```{r, echo=FALSE, out.width = "50%"}
# Student ID, Total Completed Exercises before and including First Solo
clean_data %>% unite("Date", c(Year, Month, Day), sep = "-") %>% 
  mutate(Date = as.Date(Date), numEx = str_count(Exercises, ",") + 1) %>% 
  group_by(Student_ID) %>% arrange(Student_ID, Date) %>% 
  mutate(totalEx = cumsum(numEx)) %>% 
  select( Student_ID, Training_Type, Date, totalEx ) %>% 
  mutate( solo_flight = str_detect(Training_Type, "solo" ) ) %>% 
  filter( solo_flight ) %>% slice(1) %>% 
  select(Student_ID, totalEx, solo_flight) %>% 
  ungroup() -> solo
  
# Student_ID Total Exercises, students that have not flown solo.
clean_data %>% unite("Date", c(Year, Month, Day), sep = "-") %>% 
  mutate(Date = as.Date(Date), numEx = str_count(Exercises, ",") + 1) %>% 
  group_by(Student_ID) %>% arrange(Student_ID, Date) %>% 
  mutate(totalEx = cumsum(numEx)) %>% 
  select( Student_ID, Training_Type, Date, totalEx ) %>% 
  mutate( solo_flight = !str_detect(Training_Type, "solo" ) ) %>% 
  filter( solo_flight ) %>% arrange(desc(Date)) %>% slice(1) %>% 
  select(Student_ID, totalEx, solo_flight) %>% 
  anti_join(clean_data %>% unite("Date", c(Year, Month, Day), sep = "-") %>% 
              mutate(Date = as.Date(Date)) %>%
              group_by(Student_ID) %>% arrange(Student_ID, Date) %>% 
              select( Student_ID, Training_Type, Date ) %>% 
              mutate( solo_flight = str_detect(Training_Type, "solo" ) ) %>% 
              filter( solo_flight ) %>% slice(1) %>% 
              select(Student_ID), by = "Student_ID") %>% 
  ungroup() -> non_solo
  non_solo %>% mutate(solo_flight = FALSE) -> non_solo
  
  # Join and create boxplot of # exercises between solo and non-solo fliers.
  solo %>% 
  union(non_solo) %>% 
  select(solo_flight, totalEx) %>% 
  mutate(solo_flight = factor(solo_flight, levels = c(FALSE,TRUE), 
                              labels = c("never flew solo", "flew solo"))) %>%
  ggplot(aes(x=solo_flight, y=totalEx)) + geom_boxplot() + 
  xlab("Solo Flight") + ylab("Exercises") + 
  ggtitle("Number of Exercises Completed vs Solo Flight") +
  theme(plot.title = element_text(hjust = 0.5))
  ```
  
The graph suggests that there is a significant difference in the number of exercises completed between both the groups.  

Hence, we conducted a hypothesis test to validate our conclusion from the graph at 5% significance level.

$H_0: \mu_{solo} - \mu_{non_solo} =0$ vs $H_A: \mu_{solo} - \mu_{non_solo} \neq 0$

```{r, echo = FALSE, warnings = FALSE}
  
  # Independence Test  to check significance of difference between exercises of solo and non-solo fliers.
  z = capture.output(solo %>% union(non_solo) %>% 
  select(solo_flight, totalEx) %>% 
  mutate(solo_flight = factor(solo_flight, levels = c(FALSE,TRUE), 
                              labels = c("non-solo", "solo"))) %>%
  coin::independence_test(totalEx ~ solo_flight, data = ., distribution = "approx"))

results_from_test = z[5] #A string so modify as you need for inline input
```

`r {results_from_test}`

We see that the P-value is indeed very strong (<0.0001). And at 5% significance level we reject the null hypothesis and accept the alternate hypothesis. Thereby, we can conclude that a solo flight is a strong metric for students' progress as it requires a certain level of prior experience and skill.
 
 We checked the training data to see if there is a specific order in which exercises should be completed. To determine the order in which the exercises should be completed, we found the session at which at least 70% of students who completed that number of sessions, completed the given exercise.
 
 ```{r, echo=FALSE, warning=FALSE}
clean_data = clean_data %>% unite("Date", Year,Month,Day,sep="-", remove=FALSE) %>% mutate(Date = ymd(Date))
ex_n_sessions = function(df, n){
  #Creates graph of proportion of students that completed each exercise at least once in their first n sessions
  first_n = df %>% group_by(Student_ID) %>%  top_n(n, desc(Date)) %>% distinct( Session_ID, .keep_all = T) %>% mutate( Exercises = str_split(Exercises, ",") ) %>%  unnest( Exercises) %>% group_by(Student_ID) %>% distinct(Exercises, .keep_all=TRUE)
  ex_cmp_proportion = data.frame(Exercise = integer(), Proportion = numeric())
  n_students = first_n %>% ungroup() %>% summarize(n_distinct(Student_ID)) %>% as.numeric()
  for (i in 1:30){
    tmp = first_n %>% ungroup() %>% filter(Exercises == as.integer(i)) %>% summarize(n = n()) %>% as.numeric()
    prop = tmp/n_students
    ex_cmp_proportion = ex_cmp_proportion %>% add_row(Exercise = i, Proportion = prop)
  }
  return(ex_cmp_proportion)
}

build_order_table = function(df, n_sessions){
  exercises = data.frame(Exercise = integer(), Expected_Session = integer())
  for (i in 1:n_sessions){
    tmp = clean_data %>% group_by(Student_ID) %>% summarize(Count = n()) %>% filter(Count >= i)
    stud_set = clean_data %>% inner_join(tmp, "Student_ID")
    prop = ex_n_sessions(stud_set, i)
    for(j in 1:30){
      if(prop[j, 2] >= 0.7){
        exercises = exercises %>% add_row(Exercise = j, Expected_Session = i)
      }
    }
  }
  exercises= exercises %>% arrange(Expected_Session) %>% distinct(Exercise, .keep_all = TRUE)
  return(exercises)
}

tbl = build_order_table(clean_data, 50) 
tbl1 = tbl %>% slice(1:8)
tbl2 = tbl %>% slice(9:16)
tbl3 = tbl %>% slice(17:24)
kable(list(tbl1,tbl2, tbl3)) %>% kable_styling(latex_options = "hold_position")
```

The above table displays the implied order of exercises based on the criteria explained above. This order seems to suggest that while exercises 1 to 5 are important to complete immediately, the later exercises require much more experience, as exercises 19, 22, 23, and 24 were not completed by 70% of students until after 40 or more sessions.

We analyzed how many students met the flight license requirements, and compared their progress.
We have analyzed how close each student has come to completing their pilot license requirement, based on each category.
The percentage of completion of the total hours requirement(45hrs needed), total solo hours requirement(12hrs needed), the total dual hours requirement(17hrs needed),
the total dual cross-country hours requirement(3hrs needed),
the total solo cross-country hours requirement(5hrs needed), and the total instrument hours requirement(5hrs needed).
Overall is the weighted mean of each category (based on hours), which is used to estimate their overall progress percentage towards their flight license.
There could be a bias, as students that have been in the program longer would have a much higher overall progress.
Thus, we graph the performance of each student against their enrollment duration in the flight school. We assume each student has completed 10 hours of pre-flight training.

```{r, warning=FALSE, out.width = "50%", fig.align = "left"}
data = clean_data
 time_stats = data  %>% select(Instructor_ID,Student_ID,Duration,Session_ID
                                                       ,Training_Type) %>%
  mutate(Solo_Time = Duration * as.integer(str_detect(Training_Type,"solo")) ,Dual_Time = Duration * as.integer(str_detect(Training_Type,"dual||Ins")),
         CC_Time_Dual = Duration * as.integer(str_detect(Training_Type,"CC_dual")),
         CC_Time_Solo = Duration * as.integer(str_detect(Training_Type,"CC_solo")),
         Ins_Dual_Time = Duration * as.integer(str_detect(Training_Type,"Ins")))%>% group_by(Instructor_ID,Student_ID,Session_ID) %>% 
  summarise(
    Total_Duration = sum(Duration),
    Total_Solo = sum(Solo_Time), Total_Dual = sum(Dual_Time), Total_CC_Dual = sum(CC_Time_Dual),
    Total_CC_Solo = sum(CC_Time_Solo), Total_Ins_Dual = sum(Ins_Dual_Time)
  ) %>%
  summarise(Total_Duration = sum(Total_Duration),Total_Solo = sum(Total_Solo), Total_Dual = sum(Total_Dual), Total_CC_Dual = sum(Total_CC_Dual),
    Total_CC_Solo = sum(Total_CC_Solo), Total_Ins_Dual = sum(Total_Ins_Dual)) %>% ungroup() %>% arrange(desc(Total_Duration))
#time_stats
percents =time_stats %>% mutate(Total_Duration = ifelse(Total_Duration>45,1,Total_Duration/45)*100,Total_Solo = 
                        ifelse(Total_Solo<12,Total_Solo/12,1)*100,Total_Dual = ifelse(Total_Dual<17,Total_Dual/17,1)*100,Total_CC_Dual = ifelse(Total_CC_Dual<3,Total_CC_Dual/3,1)*100 ,Total_CC_Solo = ifelse(Total_CC_Solo<5,Total_CC_Solo/5,1)*100 ,Total_Ins_Dual = ifelse(Total_Ins_Dual<5,Total_Ins_Dual/5,1)*100,Overall = Total_Duration*45/87+Total_Solo*12/87+Total_Dual*17/87+Total_CC_Dual*3/87+Total_CC_Solo*5/87+Total_Ins_Dual*5/87)%>%
 arrange(desc(Overall))
tbl1 = percents%>%select(Student_ID,Overall) %>% slice(1:10)
tbl2 = percents%>%select(Student_ID,Overall) %>% slice(11:20)
tbl3 = percents%>%select(Student_ID,Overall) %>% slice(21:30)
kable(list(tbl1,tbl2,tbl3), caption="Top 30 Students by Course Completion")
```

```{r, echo=FALSE, out.width="50%", fig.align = "center"}
Student_Time = data %>% unite("Date", c(Year, Month, Day), sep = "-") %>% 
  mutate(Date = as.Date(Date)) %>% group_by(Instructor_ID,Student_ID) %>% 
  distinct(Session_ID,.keep_all = T) %>% mutate(Diff = Date - lag(Date)) %>%
  summarise(Time = sum(Diff,na.rm=T)) %>% ungroup()
#percents %>% inner_join(Student_Time,by = c("Student_ID","Instructor_ID")) %>%
#  ggplot(aes(x=Time,y=Total_Duration))+ geom_col() +geom_smooth()
#percents %>% inner_join(Student_Time,by = c("Student_ID","Instructor_ID")) %>%
#  ggplot(aes(x=Time,y=Total_CC_Dual))+ geom_col() +geom_smooth()
#percents %>% inner_join(Student_Time,by = c("Student_ID","Instructor_ID")) %>%
#  ggplot(aes(x=Time,y=Total_CC_Solo))+ geom_col()+geom_smooth()
#percents %>% inner_join(Student_Time,by = c("Student_ID","Instructor_ID")) %>%
#  ggplot(aes(x=Time,y=Total_Dual))+ geom_col()+geom_smooth()
#percents %>% inner_join(Student_Time,by = c("Student_ID","Instructor_ID")) %>%
#  ggplot(aes(x=Time,y=Total_Solo))+ geom_col()+geom_smooth()
percents %>% inner_join(Student_Time,by = c("Student_ID","Instructor_ID")) %>% 
  ggplot(aes(x=Time,y=Overall))+ geom_point()+geom_smooth()+labs(title = "Overall Percentage Completion VS Time in Flight School",x = "Time in School",y="Overall % completed")
```

We observed that only Student# 88 completed all the requirements for the pilot's license, however multiple students have come very close to completion.
Furthermore, from our graph, we see that students that come close to completion, do so in a varying amount of time. Thus we hypothesize that students finish the course at their own pace.
We can also see a linear trend in the beginning of the graph which becomes somewhat logarithmic later. This is due to the high number of beginner students with low completion percentages, and the students that complete the course in a longer period of time.

## Summary 

We concluded there are several aspects of the training school's training process that can be adjusted to create a more efficient system. More efficient instructors should be assigned more students, especially during busy periods. This will allow the flight school to maximize the number of students going through the school and thus will increase profits. Additionally, the flight school should aim to train more students in the month of September as wind conditions are similar to the month of August but total air traffic decreases, thus making flying in September safer. A benchmark for student success was determined to be the student's first solo flight. Taking a measure of when 70% of students had completed a specific exercise, we derived a suggested order of exercises. Finally, we concluded that there is currently no set pace for completing the flight course as students with varying course completion have been in the course for inconsistent periods of time.
