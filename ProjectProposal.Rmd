---
output:
  pdf_document: default
  html_document: default
---

```{r, echo=FALSE, warning=FALSE, results=FALSE, message=FALSE}
#This is the initial data processing code that Prof. Damouras gave us. The only part of this block that was changed by Alec was filtering out all data points with no duration data.
library(tidyverse)
rm(list = ls())

raw_data = NULL
for( i in 1:17){
  tmp = readxl::read_xlsx( "data/STAA57 Initial Data.xlsx", skip = 1, sheet = i, 
                                     col_names =  paste( "X", 1:12, sep="" ) ) %>% 
    mutate( Instructor_ID = i,
            PPL = X1,
            X1 = replace( X1, !str_detect(X1, "Student"), NA ),
            PPL = zoo::na.locf( PPL ),
            X1 = zoo::na.locf(X1) )
  raw_data = bind_rows( raw_data, tmp )
}
rm(tmp,i)

names( raw_data  ) = c( "Student", "Year", "Month", "Day", "Aircraft", "LF_dual", 
"LF_solo", "Instrument_AC",  "Instrument_Sim", "CC_dual", "CC_solo", "Exercises",
"Instructor_ID", "Licence")

head(raw_data)

raw_data %>%
  filter( !is.na(Year), Year != "Year",
          Exercises != "*NO DATA") %>% 
  mutate_at( .vars = c(2:4), .funs = as.integer ) %>% 
  mutate_at( .vars = c(6:11), .funs = as.numeric ) %>% 
  mutate( Aircraft = str_to_upper(Aircraft),
          Aircraft = replace( Aircraft, str_detect(Aircraft, "GROUND"), "GROUND"),
          Aircraft = replace_na( Aircraft, "NA"),
          Other = ifelse( str_detect(Aircraft,"GROUND|NA"), -1, NA ),
          Student_ID = as.numeric( factor( paste( Student, Instructor_ID) ) ), 
          Session_ID = row_number() ) %>% 
  gather( key = "Training_Type", value = "Duration", 6:11, Other) %>% 
  filter( !is.na(Duration) ) %>% 
  mutate( Duration  = na_if(Duration, -1),
          Aircraft = na_if(Aircraft, "NA")) %>% 
  select( Instructor_ID, Student_ID, Session_ID, Year, Month, Day, 
          Aircraft, Duration, Training_Type, Exercises, Licence ) %>% 
          filter(! is.na(Duration)) -> clean_data

clean_data %>% 
  distinct( Session_ID, .keep_all = T) %>% 
  # split the exercises string into a "list" column w str_split()
  mutate( Exercises = str_split(Exercises, ",") ) %>%  
  # and expand list contents into multiple rows w/ unnest()
  unnest( Exercises)
  
```

```{r, echo=FALSE, warning=FALSE, message=FALSE}
#Starting here, this is my own code.

# This for loop iterates through each training session's year data. If the year is listed below 2015, it replaces the year with the year of the entries above and below it (assuming they match, but there have been no cases where they didn't in our data sets).
# This works, as by this point in the processing, sessions are sorted by date for each instructor, then by each student.
for (i in 2:nrow(clean_data)-1){
  if (clean_data[i,4] < 2015 && clean_data[i-1,4] == clean_data[i+1,4]){
    clean_data[i,4] = clean_data[i-1,4]
  }
}



#This loop does the same as the one above but with replacing month values > 12 with the month of an adjacent datapoint from the same student.
for (i in 2:nrow(clean_data)-1){
  if (clean_data[i,5] > 12 && clean_data[i-1,2] == clean_data[i,2]){
    clean_data[i,5] = clean_data[i-1,5]
  }
  else if (clean_data[i,5] > 12 && clean_data[i+1,2] == clean_data[i,2]){
    clean_data[i,5] = clean_data[i+1,5]
  }
}

# This line removes all non comma separators including periods, spaces, double commas, and backticks as well as leading and trailing commas.
clean_data$Exercises = clean_data$Exercises %>% str_replace("^,", "") %>% str_replace_all(",$", "") %>% str_replace_all("\\`", "1") %>% str_replace_all("[:punct:]", ",") %>% str_replace_all("[:blank:]", ",") %>% str_replace_all(",,", ",")

#This algorithm deletes every extra errant data points that have listed exercises above 30 (It's safer to delete these points than to assume we know what they are)
invalid_points = c()

for (i in 1:nrow(clean_data)){
  exercises = clean_data[i,10]
  is_invalid = FALSE
  last_comma = 0
  for (j in 1:nchar(exercises)){
    if (substr(exercises, j, j) ==  ","){
      q = substr(exercises, last_comma+1, j-1)
      if (strtoi(substr(exercises, last_comma+1, j-1)) > 30){
        is_invalid = TRUE
      }
      last_comma = j
    }
    if (j == nchar(exercises)){
      if (strtoi(substr(exercises, last_comma+1, j)) > 30){
        is_invalid = TRUE
      }
    }
  }
  if (is_invalid == TRUE){
    invalid_points = append(invalid_points, clean_data[i, 10])
  }
}

for (i in 1:length(invalid_points)){
  clean_data = clean_data %>% filter(Exercises != invalid_points[i])
}
```

# STAA57 Project Proposal
`Avoid deleting other people's work when possible (anything in backticks is not intended to be final and can be deleted)`
`Document Length: ~2 pages`

### Analysis Plan
`Specify questions to be addressed`

With the data given and additional data on monthly air traffic, weather and seasons, the following questions will be adressed by our analysis:
  
  - **How can scheduling be made the most efficient?
    - Is each instructor getting the appropriate number of hours?
    - Which season(s) see the best average student performance?
    - Time between each sessions
    - How many students come in every month/ how many sessions?
  
  - **What are the optimal conditions for student success?
    - Which training type yields the highest efficiency (by exercises completed per training hour)?
    - Exercises per hour of training (Only works for long term data)
    - Milestones achieved (Like flying solo, completing all exercises at least once?)
    - If solo flight hypothesis has significant correlation, school is doing well to judge when to do solo flights. If no correlation, flight school either is not judging solo        flights well or there is no relationship between when a student takes a solo flight and what they have accomplished.
    - *Instructor/student data relationship (Do some students fare better with certain instructors?)*
    
    Just a few questions I thought you should consider while writing the description.
    1) How long/many sessions did students train before flying solo?
    2) How long/many sessions did they fly dual? local? A particular aircraft?
    3) Was there a common set of exercises that was required?
    4) How was the first solo flight? (Did they fly solo again?)
    5) What was the weather like?
    6) Do our answers to the above questions change with instructors?
    7) How does the above information relate with students that never flew solo?
    
  - **What defines success/effectiveness of training?
    - Analysis for individual students' milestone that have hit milestones vs those who have not
    - Have all/most students who have flown solo done something the non-solo students haven't?    
    - **As an extension, can we determine what benchmarks students should/have to meet in order to fly solo?
  
In answering these questions, we made the assumption in analyzing our data that all students begin their training at the same skill level. Additionally, we assume there were no unmeasurable external factors impacting the duration or efficiency of sessions. That is to say, unless a factor can be measured, it cannot be accounted for in our analysis.

Our analysis plan consists of answering the following sub-questions related to the main questions we seek to answer:

Our group has several different approaches to getting the most useful conclusions out of this data.

### Data
`List/specify external data sources and types of data`
`R Code for importing data will not go in this section (since it is 100+ lines, ideally it goes in the appendix)`

To help determine when air traffic is the lowest, and thus flight accident risk is the lowest, we acquired air traffic data from the supplemmentary data. 
Air Traffic - https://open.canada.ca/data/en/dataset/b91772ed-edae-4fd4-8b80-a3e4c1d29976

```{r, echo=FALSE, warning=FALSE}
air_movements <- read_csv("ext-data/aircraft-movements/23100003.csv") %>% 
  filter( Airports == "Oshawa, Ontario",  str_detect(REF_DATE, "2015|2016|2017|2018|2019|2020") ) %>% 
  select( REF_DATE, `Civil and military movements`, VALUE) %>%
  separate(REF_DATE, c("Year", "Month"), sep = "-") %>% 
  mutate(Year = as.integer(Year), Month = as.integer(Month))
```

To determine when flying is the safest (lowest wind, lowest precipitation), we used weather data from Government Of Canada's Website.
Weather data - https://climate.weather.gc.ca/historical_data/search_historic_data_e.html

```{r,  echo=FALSE, warning=FALSE}
read_csv("data/en_climate_daily_ON_6155875_2015_P1D.csv", 
         col_types = cols(Year = col_integer(), Month = col_integer(), Day = col_integer())) %>% 
  select(Year, Month, Day, `Max Temp (°C)`, `Min Temp (°C)`, `Mean Temp (°C)`, `Heat Deg Days (°C)`,
         `Cool Deg Days (°C)`, `Total Precip (mm)`, `Spd of Max Gust (km/h)`) -> weather

for(i in 2016:2020) {
  loc = c("data/en_climate_daily_ON_6155875_", as.character(i), "_P1D.csv")
  read_csv(str_c(loc, collapse = ""),
           col_types = cols(Year = col_integer(), Month = col_integer(), Day = col_integer(),
                            `Spd of Max Gust (km/h)` = col_character())) %>% 
    select(Year, Month, Day, `Max Temp (°C)`, `Min Temp (°C)`, `Mean Temp (°C)`, `Heat Deg Days (°C)`,
           `Cool Deg Days (°C)`, `Total Precip (mm)`, `Spd of Max Gust (km/h)`) %>% union(weather) -> weather }
```

### Preliminary Analysis
`Put in >= 3 graphs/DaVis' relating to analysis and comment on preliminary findings.`

To properly establish the  most efficient method of training students, first we must establish a measure of efficiency. By graphing exercises completed in each individual session, we determined that on a session by session basis, the exercises completed cannot be related to the duration of the session. However, by graphing the total session hours completed against the total exercises completed under each instructors supervision, we found that there is a significant correlation between training time and the number of exercises completed in the long term.

```{r, echo=FALSE, warnings=FALSE}
new_clean_data = clean_data %>% mutate(Exercise_Count = str_count(Exercises, ',') + 1)

# Graphing Information on Instructors
Instructor_Data = new_clean_data %>% group_by(Instructor_ID) %>% summarise(Total_Hours = sum(Duration), Total_Exercises = sum(Exercise_Count), Hourly_Exercises = Total_Exercises/Total_Hours, Average_Hours = (sum(Duration)/(max(Year) - min(Year))))

# Graph total hours against total exercises students completed under each instructor (with line of best fit and r value
Coeftext = paste("r =" , toString(cor(Instructor_Data %>% select(Total_Hours), Instructor_Data %>% select(Total_Exercises), method = c("pearson"))[1][1]))
ggplot(data = Instructor_Data, aes(x = Total_Hours, y = Total_Exercises)) + geom_point()  +
  geom_smooth(method='lm', formula= y~x, se = FALSE)+  geom_text(aes(x = 250, y = 300), label = Coeftext) +
  ggtitle("Hours of Instruction by Instructors vs Total Exercises Students Completed")
```
Since both Total Hours and Total Exercises are roughly continuous, we can use calculate Pearson's Linear Correlation Coefficient
We found that r ~ 0.98, which shows strong positive correlation between the variables. Given this, we concluded that for analysis spanning several months or years, the number of exercises completed per hour is a reliable efficiency metric.

From this efficiency metric, we graphed the average hours each instructor worked per year against the average number of exercises students completed per hour.
``` {r, echo=FALSE, warnings=FALSE}
ggplot(data = Instructor_Data, mapping = aes(x = Average_Hours, y = Hourly_Exercises)) + geom_point() + geom_smooth(method = 'lm', formula = y~x, se = FALSE) + ggtitle("Average Hours Instructed per Year vs Average Hourly Exercises Students Completed")
```
This graph clearly shows no clear correlation between average yearly hours worked and the exercises completed per hour by students. This lead us to conclude that instructors do not necessarily get better the more frequently they teach, but rather that some instructors are more effective than others. The line of best fit on this graph is not to show correlation but rather to plot the expected hours that each instructor should get based on their efficiency. Points above the line are, by our metric getting too few hours and instructors below the line are being scheduled for too many hours.

### Appendix
`R Code for cleaning and importing data goes here (I am rewriting my code to be more space efficient. If I can compress it enough, I might be able to move it into the data section`
